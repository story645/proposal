\documentclass[../main.tex]{subfiles}

\begin{document}
\section{Discussion}

This work contributes a mathematical description of the transformation from data to visual representation. Combining Butler's fiber bundle model of data with Spivaks formalism of data schemas provides a way of decoupling topology from variability such that the model can support a very large variety of datasets, including discrete relational tables, multivariate high resolution spatio temporal datasets, and complex networks. Modeling the graphic as a fiber bundle provides a way to separate the target display space from the topology of the graphic. By decomposing the mapping from data to visual representation as encoding \vchannel, assembly \vmark, and a mapping between data and graphic topologies \vindex and formalizing what equivariance each stage needs to preserved, this work derives constraints that visualization library authors could embed in their code to guarantee visualizations that are equivariant transforms of the input data. 

This work generalizes previous research constraining visual encodings from data components to graphic components as equivariant maps to components that are N-dimensional. Furthermore, it precisely defines the glyph as the visual element constructed from data on a simplex in a simplacial complex where the simplex is discrete or continuous. This is a restatement of for example Bertin's definition of a line that encapsulates all points on the continuous line.  By modeling the data topology along with its variablity, this work also provides  a generalization of topology preservation as a deformation retraction from graphic space to data space. By using a functional paradigm, we can deconstruct the graphic to the glyph associated with each data point or even to pieces of a glyph; therefore the renderer has full  flexibility in how to to generate the image, while the graphic to data topology maps provide a way to keep track of which part of the image belongs to which data point. 

The toy prototype built using this model validates that is usable for a general purpose visualization tool since it can be iteratively integrated into the existing architecture rather than starting from scratch/ Factoring out glyph formation into assembly functions allows for much more clarity in how the glyphs differ. This prototype demonstrates that this framework can generate the fundemental marks, point (scatter plot), line (line chart), and area (bar chart). Furthermore, the grouped and stacked bar examples demonstrate that this model supports composition of glyphs into more complex graphics. These composite examples also rely on the fiber bundles section base book keeping to keep track of which components contribute to the attributes of the glyph. Implementing this example using a Pandas dataframe demonstrates the ease of incorporating existing widely used data containers rather than requiring users to conform to one stands.  

\subsection{Limitations}

So far this model has only been worked out for a single data set tied to a primitive mark, but it should be extensible to compositing datasets and complex glyphs. The examples and prototype have so far only been implemented for the static 2D case, but nothing in the math limits to 2D and expansion to the animated case should be possible because the model is formalized in terms of the sheaf. While this model supports equivariance of figurative glyphs generated form parameters of the data\cite{beckfeathers2014,byrneFigurativeFramesCritical2017}, it currently does not have a way to evaluate the semantic accuracy of the figurative representation. This model also does not currently factor in effectiveness, but potentially effectiveness criteria could be incorporated into a scheme for assigning encoders and assembling glyphs. This model and the associated prototype is deeply tied to Matplotlib's existing architecture. While the model is expected to generalize to other libraries, such as those built on Mackinlay's APT framework, this has not been worked through. Even though the model is designed to be backend independent, it has only really been tested against the AGG backend. It is especially unknown how this framework interfaces with high performance rendering libraries such as openGL\cite{CarsonOpenGL1997}.

\subsection{Next Steps}
While the model and prototype demonstrate that generation of simple marks from the data, there is a lot of work left to develop a model that underpins a minimally viable library. While the model supports simple composition of glyphs by overlaying glyphs at the same position, more work is needed to define an operator where the fiber bundles have shared $\gbase_2 \hookrightarrow \gbase_1$ such that fibers could be pulled back over the subset. This complex operator is necessary for building semantically meaningful components such as axes labels and interactive visualizations that update on shared \gbase, such as brush-linked views\cite{} 


%%%An interesting control problem will be how to keep the text and graphics consistent. If the rendering exchanges the horizontal and vertical axes of a bar chart, the text must also exchange its references to the axes.
\begin{itemize}
    \item is compose(encodes) and ggplot is plot(encodes, glyph)
    \item heatmaps/ proof of concept of face simplex
    \item composition algebra
    \item boxplot - multiglyph composition
    \item debatable: non-trivial bundle like data on mobius backend
    \item interactivity 
    \item concurrent artist
    \item numpy wrapper
    \item layout
    \item text
    \item keeping all data in sync if transform is changed in one place (so on multi composed graphs, changing x on does it propopgate - part of Bertin invariance)
\end{itemize}
\begin{itemize}
    \item provisional implementation using new architecture in Matplotlib
    \item developer-aimed documentation (API + narrative)
    \item proof of concept 3rd party user-facing library with a biology partner
    \item academic paper about building visualization tools on top of the core architecture
\end{itemize}

Other things that may or may not play a big role would be working out the details of the S->K interaction for dashboards. By this I particularly mean when S is a composite object spanning all the figures shown in the dashboard and a component of K may have different components of S mapping into it slicing it in different ways.
\subsection{What are the lessons learned?}

\end{document}

